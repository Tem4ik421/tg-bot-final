import os
import time
import threading
import base64
import requests
import json
from flask import Flask, request
import telebot
from telebot import types
from datetime import datetime
from fpdf import FPDF
import feedparser
import google.generativeai as genai

# üîê –ö–ª—é—á–∏ –∏ –º–æ–¥–µ–ª–∏
TOKEN = os.getenv("TELEGRAM_BOT_TOKEN")
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY")
WEBHOOK_HOST = os.getenv("WEBHOOK_HOST") or "https://your-render-url.onrender.com"
WEBHOOK_PATH = f"/{TOKEN}"
WEBHOOK_URL = f"{WEBHOOK_HOST}{WEBHOOK_PATH}"

MODEL_TEXT = "models/gemini-2.5-pro"
MODEL_IMAGE = "imagen-4.0"

genai.configure(api_key=GEMINI_API_KEY)
bot = telebot.TeleBot(TOKEN, parse_mode="HTML")
app = Flask(__name__)

# üíæ –ò—Å—Ç–æ—Ä–∏—è –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π
HISTORY_FILE = "user_history.json"
if os.path.exists(HISTORY_FILE):
    with open(HISTORY_FILE, "r") as f:
        user_history = json.load(f)
else:
    user_history = {}

def save_history():
    with open(HISTORY_FILE, "w") as f:
        json.dump(user_history, f)

# üí§ –ê–Ω—Ç–∏—Ñ—Ä–∏–∑
def keep_alive():
    while True:
        try:
            requests.get(WEBHOOK_HOST)
            print("üí§ Ping ‚Üí Render OK")
        except Exception as e:
            print("‚ö†Ô∏è Ping Error:", e)
        time.sleep(600)

threading.Thread(target=keep_alive, daemon=True).start()

# –ì–ª–∞–≤–Ω–æ–µ –º–µ–Ω—é
def main_menu():
    markup = types.ReplyKeyboardMarkup(resize_keyboard=True)
    markup.row("üë§ –ü—Ä–æ—Ñ–∏–ª—å")
    markup.row("üñºÔ∏è –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –ú–µ–¥–∏–∞", "‚öì –ú–æ—Ä—Å–∫–∏–µ –Ω–æ–≤–æ—Å—Ç–∏")
    markup.row("üé® –°–æ–∑–¥–∞—Ç—å –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—é", "‚ùì –û—Ç–≤–µ—Ç—ã –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã")
    return markup

# /start
@bot.message_handler(commands=["start"])
def start(message):
    chat_id = str(message.chat.id)
    user_history.setdefault(chat_id, {"questions": [], "media": [], "presentations": [], "news": []})
    save_history()
    bot.send_message(chat_id, f"–ü—Ä–∏–≤–µ—Ç, {message.from_user.first_name}! üëã\n–í—ã–±–µ—Ä–∏ –æ–ø—Ü–∏—é:", reply_markup=main_menu())

# üë§ –ü—Ä–æ—Ñ–∏–ª—å
@bot.message_handler(func=lambda m: m.text == "üë§ –ü—Ä–æ—Ñ–∏–ª—å")
def profile(message):
    chat_id = str(message.chat.id)
    hist = user_history.get(chat_id, {})
    text = (
        f"üßæ –ü—Ä–æ—Ñ–∏–ª—å\n"
        f"üÜî ID: {chat_id}\n"
        f"üë§ Username: @{message.from_user.username}\n"
        f"üìÖ –î–∞—Ç–∞: {datetime.now().strftime('%Y-%m-%d')}\n\n"
        f"üìä –í–æ–ø—Ä–æ—Å–æ–≤: {len(hist['questions'])}\n"
        f"üñºÔ∏è –ú–µ–¥–∏–∞: {len(hist['media'])}\n"
        f"üìò –ü—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–π: {len(hist['presentations'])}\n"
        f"‚öì –ù–æ–≤–æ—Å—Ç–µ–π: {len(hist['news'])}"
    )
    markup = types.ReplyKeyboardMarkup(resize_keyboard=True)
    markup.row("üìã –ò—Å—Ç–æ—Ä–∏—è –¥–µ–π—Å—Ç–≤–∏–π")
    markup.row("‚¨ÖÔ∏è –ù–∞–∑–∞–¥ –≤ –º–µ–Ω—é")
    bot.send_message(chat_id, text, reply_markup=markup)

@bot.message_handler(func=lambda m: m.text == "üìã –ò—Å—Ç–æ—Ä–∏—è –¥–µ–π—Å—Ç–≤–∏–π")
def history_details(message):
    chat_id = str(message.chat.id)
    hist = user_history.get(chat_id, {})
    text = "üìã –ò—Å—Ç–æ—Ä–∏—è:\n\n"
    text += "‚ùì –í–æ–ø—Ä–æ—Å—ã:\n" + "\n".join(hist["questions"][-5:] or ["‚Äî"]) + "\n\n"
    text += "üñºÔ∏è –ú–µ–¥–∏–∞:\n" + "\n".join(hist["media"][-5:] or ["‚Äî"]) + "\n\n"
    text += "üìò –ü—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏:\n" + "\n".join(hist["presentations"][-3:] or ["‚Äî"]) + "\n\n"
    bot.send_message(chat_id, text)

# üñºÔ∏è –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –º–µ–¥–∏–∞
@bot.message_handler(func=lambda m: m.text == "üñºÔ∏è –ì–µ–Ω–µ—Ä–∞—Ç–æ—Ä –ú–µ–¥–∏–∞")
def media_menu(message):
    markup = types.ReplyKeyboardMarkup(resize_keyboard=True)
    markup.row("üì∏ –§–æ—Ç–æ", "üé¨ –í–∏–¥–µ–æ (–≤ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ)")
    markup.row("‚¨ÖÔ∏è –ù–∞–∑–∞–¥ –≤ –º–µ–Ω—é")
    bot.send_message(message.chat.id, "–í—ã–±–µ—Ä–∏—Ç–µ —Ç–∏–ø –º–µ–¥–∏–∞:", reply_markup=markup)

@bot.message_handler(func=lambda m: m.text == "üì∏ –§–æ—Ç–æ")
def ask_image_prompt(message):
    msg = bot.send_message(message.chat.id, "‚úèÔ∏è –í–≤–µ–¥–∏—Ç–µ –æ–ø–∏—Å–∞–Ω–∏–µ (–Ω–∞–ø—Ä–∏–º–µ—Ä: ¬´–∫–æ—Ç –≤ —Å–∫–∞—Ñ–∞–Ω–¥—Ä–µ –Ω–∞ –ú–∞—Ä—Å–µ, —Ä–µ–∞–ª–∏—Å—Ç–∏—á–Ω–æ¬ª)")
    bot.register_next_step_handler(msg, generate_image)

def generate_image(message):
    chat_id = str(message.chat.id)
    prompt = message.text
    loading = bot.send_message(chat_id, "üîÑ –ì–µ–Ω–µ—Ä–∏—Ä—É—é —Ñ–æ—Ç–æ —á–µ—Ä–µ–∑ Imagen 4.0‚Ä¶ ü™Ñ")

    try:
        url = f"https://generativelanguage.googleapis.com/v1beta/models/{MODEL_IMAGE}:predict?key={GEMINI_API_KEY}"
        payload = {"instances": [{"prompt": {"text": prompt}}]}
        headers = {"Content-Type": "application/json"}
        response = requests.post(url, json=payload, headers=headers)
        data = response.json()

        image_base64 = data["predictions"][0]["bytesBase64Encoded"]
        image_bytes = base64.b64decode(image_base64)
        filename = f"generated_{chat_id}.png"
        with open(filename, "wb") as f:
            f.write(image_bytes)

        bot.delete_message(chat_id, loading.message_id)
        bot.send_photo(chat_id, open(filename, "rb"))
        user_history[chat_id]["media"].append(prompt)
        save_history()
    except Exception as e:
        bot.delete_message(chat_id, loading.message_id)
        bot.send_message(chat_id, f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {e}")

# ‚öì –ú–æ—Ä—Å–∫–∏–µ –Ω–æ–≤–æ—Å—Ç–∏
@bot.message_handler(func=lambda m: m.text == "‚öì –ú–æ—Ä—Å–∫–∏–µ –Ω–æ–≤–æ—Å—Ç–∏")
def maritime_news(message):
    chat_id = str(message.chat.id)
    bot.send_message(chat_id, "üåä –ü–æ–ª—É—á–∞—é –∞–∫—Ç—É–∞–ª—å–Ω—ã–µ –º–æ—Ä—Å–∫–∏–µ –Ω–æ–≤–æ—Å—Ç–∏‚Ä¶")
    feed = feedparser.parse("https://news.un.org/feed/subscribe/ru/news/topic/sea/feed/rss.xml")
    for e in feed.entries[:3]:
        bot.send_message(chat_id, f"<b>{e.title}</b>\n{e.link}")
    user_history[chat_id]["news"].append(datetime.now().isoformat())
    save_history()

# üé® –ü—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏
@bot.message_handler(func=lambda m: m.text == "üé® –°–æ–∑–¥–∞—Ç—å –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—é")
def create_presentation(message):
    chat_id = str(message.chat.id)
    bot.send_message(chat_id, "üé® –°–æ–∑–¥–∞—é –∂—É—Ä–Ω–∞–ª—å–Ω—É—é –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—é —á–µ—Ä–µ–∑ Gemini 2.5 Pro‚Ä¶")

    try:
        model = genai.GenerativeModel(MODEL_TEXT)
        prompt = "–°–æ–∑–¥–∞–π –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—é –≤ –∂—É—Ä–Ω–∞–ª—å–Ω–æ–º —Å—Ç–∏–ª–µ –æ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—è—Ö –±—É–¥—É—â–µ–≥–æ, —Å 5 –∫–æ—Ä–æ—Ç–∫–∏–º–∏ —Ä–∞–∑–¥–µ–ª–∞–º–∏."
        result = model.generate_content(prompt)
        text = result.text or "–û—à–∏–±–∫–∞ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ —Ç–µ–∫—Å—Ç–∞."

        pdf = FPDF()
        pdf.add_page()
        pdf.set_font("Arial", "B", 16)
        pdf.multi_cell(0, 10, "üì∞ –ü—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏—è Gemini 2.5 Pro\n\n" + text)
        filename = f"presentation_{chat_id}.pdf"
        pdf.output(filename)
        bot.send_document(chat_id, open(filename, "rb"))
        user_history[chat_id]["presentations"].append(filename)
        save_history()
    except Exception as e:
        bot.send_message(chat_id, f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —Å–æ–∑–¥–∞–Ω–∏–∏ –ø—Ä–µ–∑–µ–Ω—Ç–∞—Ü–∏–∏: {e}")

# ‚ùì –û—Ç–≤–µ—Ç—ã –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã
@bot.message_handler(func=lambda m: m.text == "‚ùì –û—Ç–≤–µ—Ç—ã –Ω–∞ –≤–æ–ø—Ä–æ—Å—ã")
def ask_question(message):
    msg = bot.send_message(message.chat.id, "üí¨ –ó–∞–¥–∞–π –≤–æ–ø—Ä–æ—Å ‚Äî —è –æ—Ç–≤–µ—á—É —á–µ—Ä–µ–∑ Gemini 2.5 Pro:")
    bot.register_next_step_handler(msg, answer_question)

def answer_question(message):
    chat_id = str(message.chat.id)
    question = message.text
    bot.send_message(chat_id, "ü§î –î—É–º–∞—é –Ω–∞–¥ –æ—Ç–≤–µ—Ç–æ–º —á–µ—Ä–µ–∑ Gemini 2.5 Pro‚Ä¶")

    try:
        model = genai.GenerativeModel(MODEL_TEXT)
        response = model.generate

